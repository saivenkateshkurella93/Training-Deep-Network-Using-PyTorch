{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Kurella_mlTrainingDeepNetwork.ipynb.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "JSiwrEoYShoS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Sai Venkatesh\n",
        "import torch\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import torch.optim as optim\n",
        "import torch.nn as nn\n",
        "import collections\n",
        "\n",
        "############################################################################\n",
        "# Data Load\n",
        "\n",
        "def data_division(batch = 4, augment = False):\n",
        "    \n",
        "    transform = transforms.Compose(\n",
        "        [transforms.ToTensor(),\n",
        "         transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
        "\n",
        "    testset = torchvision.datasets.CIFAR10(root='./data', train=False,\n",
        "                                           download=True, transform=transform) # change download True when submit\n",
        "    testloader = torch.utils.data.DataLoader(testset, batch_size=batch,\n",
        "                                             shuffle=False, num_workers=2)\n",
        "    if augment:\n",
        "        transform = transforms.Compose(\n",
        "                    [transforms.RandomHorizontalFlip(),\n",
        "                     transforms.RandomCrop(size=[32,32], padding=4),\n",
        "                     transforms.ToTensor(),\n",
        "                     transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
        "\n",
        "    trainset = torchvision.datasets.CIFAR10(root='./data', train=True,\n",
        "                                            download=True, transform=transform) # change download True when submit\n",
        "    trainloader = torch.utils.data.DataLoader(trainset, batch_size=batch,\n",
        "                                              shuffle=True, num_workers=2)\n",
        "\n",
        "\n",
        "    classes = ('plane', 'car', 'bird', 'cat',\n",
        "               'deer', 'dog', 'frog', 'horse', 'ship', 'truck')\n",
        "    return(trainloader, testloader, classes)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Xfcn_DPYTpwP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "##########################################################################\n",
        "# Train and test the network for each epoch\n",
        "\n",
        "def train_test_network(trainloader, testloader, net, criterion, optimizer, epochs = 2, onehotencoding = False):\n",
        "    #Train\n",
        "    train_accuracy = collections.defaultdict(int)\n",
        "    loss_dic = collections.defaultdict(int)        \n",
        "    train_correct = 0\n",
        "    train_total = 0\n",
        "    \n",
        "    #Test\n",
        "    test_accuracy = collections.defaultdict(int)    \n",
        "    test_correct = 0\n",
        "    test_total = 0\n",
        "    \n",
        "    for epoch in range(epochs):  # loop over the dataset multiple times\n",
        "    ########################################################################\n",
        "    # Train the network\n",
        "        running_loss = 0.0\n",
        "        for i, data in enumerate(trainloader, 0):\n",
        "            # get the inputs\n",
        "            inputs, labels = data\n",
        "            if onehotencoding:\n",
        "                labels = onehot(labels.view(labels.shape[0],1),labels.shape[0],10)\n",
        "\n",
        "            # zero the parameter gradients\n",
        "            optimizer.zero_grad()\n",
        "\n",
        "            # forward + backward + optimize\n",
        "            outputs = net(inputs)\n",
        "            \n",
        "            _, predicted = torch.max(outputs.data, 1)\n",
        "            train_total += labels.size(0)\n",
        "            train_correct += (predicted == labels).sum().item()\n",
        "            accuracy = (100 * train_correct / train_total)\n",
        "            loss = criterion(outputs, labels)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            # print statistics\n",
        "            running_loss += loss.item() # loss is a tensor\n",
        "            if i % 2000 == 1999:    # print every 2000 mini-batches\n",
        "                #print(running_loss)\n",
        "                print('[%d, %5d] loss: %.3f' %\n",
        "                      (epoch + 1, i + 1, running_loss / 2000))\n",
        "                loss_dic[epoch + 1] = running_loss / 2000\n",
        "                running_loss = 0.0\n",
        "                \n",
        "        train_accuracy[epoch + 1] = accuracy\n",
        "        \n",
        "    ########################################################################\n",
        "    # Test the network\n",
        "        with torch.no_grad(): #no gradient descent\n",
        "            for data_test in testloader:\n",
        "                images, labels_test = data_test\n",
        "                outputs_test = net(images)\n",
        "                _, predicted_test = torch.max(outputs_test.data, 1)\n",
        "                test_total += labels_test.size(0)\n",
        "                test_correct += (predicted_test == labels_test).sum().item()\n",
        "\n",
        "            #print('Accuracy of the network on the 10000 test images: %d%%' % (100 * test_correct / test_total))\n",
        "            test_accuracy[epoch + 1] = (100 * test_correct / test_total)\n",
        "        \n",
        "\n",
        "    print('Finished Training')\n",
        "    return(train_accuracy, loss_dic, test_accuracy)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GI8WnYWuTxtV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "############################################################################\n",
        "# Train and test the network for each epoch\n",
        "\n",
        "def train_test_networkMSE(trainloader, testloader, net, criterion, optimizer, epochs = 2, onehotencoding = False):\n",
        "    #Train\n",
        "    train_accuracy = collections.defaultdict(int)\n",
        "    loss_dic = collections.defaultdict(int)        \n",
        "    train_correct = 0\n",
        "    train_total = 0\n",
        "    \n",
        "    #Test\n",
        "    test_accuracy = collections.defaultdict(int)    \n",
        "    test_correct = 0\n",
        "    test_total = 0\n",
        "    \n",
        "    for epoch in range(epochs):  # running loop over the dataset multiple times\n",
        "    ########################################################################\n",
        "    # Train the network\n",
        "        running_loss = 0.0\n",
        "        for i, data in enumerate(trainloader, 0):\n",
        "            # get the inputs\n",
        "            inputs, labels = data\n",
        "            if onehotencoding:\n",
        "                labels = onehot(labels.view(labels.shape[0],1),labels.shape[0],10)\n",
        "\n",
        "            # set the parameter gradients to zero\n",
        "            optimizer.zero_grad()\n",
        "\n",
        "            # forward + backward + optimize\n",
        "            outputs = net(inputs)\n",
        "            \n",
        "            _, predicted = torch.max(outputs.data, 1)\n",
        "            train_total += labels.size(0)\n",
        "            print(predicted)\n",
        "            print(labels)\n",
        "            train_correct += (predicted == labels).sum().item()\n",
        "            accuracy = (100 * train_correct / train_total)\n",
        "            loss = criterion(outputs, labels)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            # print statistics obtained\n",
        "            running_loss += loss.item() # loss is a tensor\n",
        "            if i % 2000 == 1999:    # print every 2000 mini-batches\n",
        "                #print(running_loss)\n",
        "                print('[%d, %5d] loss: %.3f' %\n",
        "                      (epoch + 1, i + 1, running_loss / 2000))\n",
        "                loss_dic[epoch + 1] = running_loss / 2000\n",
        "                running_loss = 0.0\n",
        "                \n",
        "        train_accuracy[epoch + 1] = accuracy\n",
        "        \n",
        "    ##########################################################################\n",
        "    # Test the network\n",
        "        with torch.no_grad(): #no gradient descent\n",
        "            for data_test in testloader:\n",
        "                images, labels_test = data_test\n",
        "                outputs_test = net(images)\n",
        "                _, predicted_test = torch.max(outputs_test.data, 1)\n",
        "                test_total += labels_test.size(0)\n",
        "                test_correct += (predicted_test == labels_test).sum().item()\n",
        "\n",
        "            #print('Accuracy of the network on the 10000 test images: %d%%' % (100 * test_correct / test_total))\n",
        "            test_accuracy[epoch + 1] = (100 * test_correct / test_total)\n",
        "            \n",
        "        #train_accuracy[epoch + 1] = net.accuracy(trainloader)\n",
        "        #test_accuracy[epoch + 1] = net.accuracy(testloader)\n",
        "\n",
        "    print('Finished Training')\n",
        "    return(train_accuracy, loss_dic, test_accuracy)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hPfVddYPT3TH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "##########################################################################\n",
        "#  Defining a Cross Entropy Loss function and a SGD optimizer\n",
        "\n",
        "def CE_loss(net, lr = 0.001):\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "    optimizer = optim.SGD(net.parameters(), lr = lr, momentum=0.9)\n",
        "    return(criterion, optimizer)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1Tfk_BqrT6-6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "########################################################################\n",
        "#  Defining a Mean Squared Error as Loss function and SGD optimizer\n",
        "\n",
        "def MSE_loss(net, lr = 0.001):\n",
        "    criterion = nn.MSELoss()\n",
        "    optimizer = optim.SGD(net.parameters(), lr = lr, momentum=0.9)\n",
        "    return(criterion, optimizer)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "US33GDgaT95g",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "########################################################################\n",
        "#  code for Plotting the graphs\n",
        "\n",
        "def plot(dictionary, title, x = \"\", y = \"\", _print = \"\", ):\n",
        "    print(_print)\n",
        "    plt.xlabel(x)\n",
        "    plt.ylabel(y)\n",
        "    plt.title(title)\n",
        "    plt.plot(list(dictionary.keys()),list(dictionary.values()),'-o')\n",
        "    plt.savefig(title + '.png')\n",
        "    plt.show()\n",
        "    plt.close()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q6W0iTUHUAtB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "##########################################################################\n",
        "#  Change the code to have only a single fully connected layer. \n",
        "#  The model will have a single layer that connects the input to the output.\n",
        "\n",
        "def single_fully_connected_model():\n",
        "    trainloader, testloader, classes = data_division(batch = 4)\n",
        "    \n",
        "    import singleFC\n",
        "    net = singleFC.Net()\n",
        "    criterion, optimizer = CE_loss(net)\n",
        "    train_accuracy, loss_dic, test_accuracy = train_test_network(trainloader = trainloader, testloader = testloader, net=net, criterion=criterion, optimizer=optimizer, epochs=25)\n",
        "    #test_accuracy = test_network(testloader = testloader, net = net)\n",
        "    plot(dictionary = train_accuracy, title = \"Single_Fully_Connected_Training_Accuracy\", x = \"Epochs\", y = \"Accuracy\", _print=  \"2. Single Fully Connected Layer - training accuracy\")\n",
        "    plot(dictionary = loss_dic, title = \"Single_Fully_Connected_Loss\", x = \"Epochs\", y = \"Loss\", _print=  \"2. Single Fully Connected Layer - loss\")\n",
        "    plot(dictionary = test_accuracy, title = \"Single_Fully_Connected_Testing_Accuracy\", x = \"Epochs\", y = \"Accuracy\", _print=  \"2. Single Fully Connected Layer - testing accuracy\")\n",
        "    print('Parameters of the network: %d' % sum(p.numel() for p in net.parameters() if p.requires_grad))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GgoXncJTUEj7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "##########################################################################\n",
        "#  Multiple fully connected layers\n",
        "\n",
        "def multiple_fully_connected_model():\n",
        "    trainloader, testloader, classes = data_division(batch = 4)\n",
        "    \n",
        "    import multipleFC\n",
        "    \n",
        "    ########################################################################\n",
        "    #  Multiple fully connected layers with ReLU\n",
        "    net = multipleFC.Net()\n",
        "    criterion, optimizer = CE_loss(net)\n",
        "    train_accuracy, loss_dic, test_accuracy = train_test_network(trainloader = trainloader, testloader = testloader, net=net, criterion=criterion, optimizer=optimizer, epochs=25)\n",
        "    plot(dictionary = train_accuracy, title = \"Multiple_Fully_Connected_ReLU_Training_Accuracy\", x = \"Epochs\", y = \"Accuracy\", _print=  \"3. Multiple Fully Connected Layer with RelU - training accuracy\")\n",
        "    plot(dictionary = loss_dic, title = \"Multiple_Fully_Connected_ReLU_Loss\", x = \"Epochs\", y = \"Loss\", _print=  \"3. Multiple Fully Connected Layer with RelU - loss\")\n",
        "    plot(dictionary = test_accuracy, title = \"Multiple_Fully_Connected_ReLU_Testing_Accuracy\", x = \"Epochs\", y = \"Accuracy\", _print=  \"3. Multiple Fully Connected Layer with RelU - testing accuracy\")\n",
        "    print('Parameters of the network: %d' % sum(p.numel() for p in net.parameters() if p.requires_grad))\n",
        "    \n",
        "    ########################################################################\n",
        "    #  Multiple fully connected layers without ReLU\n",
        "    net = multipleFC.Net(relu = False)\n",
        "    criterion, optimizer = CE_loss(net)\n",
        "    train_accuracy, loss_dic, test_accuracy = train_test_network(trainloader = trainloader, testloader = testloader, net=net, criterion=criterion, optimizer=optimizer, epochs=25)\n",
        "    plot(dictionary = train_accuracy, title = \"Multiple_Fully_Connected_Training_Accuracy\", x = \"Epochs\", y = \"Accuracy\", _print=  \"3. Multiple Fully Connected Layer without ReLU - training accuracy\")\n",
        "    plot(dictionary = loss_dic, title = \"Multiple_Fully_Connected_Loss\", x = \"Epochs\", y = \"Loss\", _print=  \"3. Multiple Fully Connected Layer without ReLU - loss\")\n",
        "    plot(dictionary = test_accuracy, title = \"Multiple_Fully_Connected_Testing_Accuracy\", x = \"Epochs\", y = \"Accuracy\", _print=  \"3. Multiple Fully Connected Layer without ReLU - testing accuracy\")\n",
        "    print('Parameters of the network: %d' % sum(p.numel() for p in net.parameters() if p.requires_grad))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B1PYBf9nUMGS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "##########################################################################\n",
        "#  Example Tutorial - two convolutional layers along with maxpooling layers before the fully connected layers\n",
        "\n",
        "def basic_tutorial_model():\n",
        "    trainloader, testloader, classes = data_division(batch = 4)\n",
        "    \n",
        "    import examplenetwork\n",
        "    net = examplenetwork.Net()\n",
        "    criterion, optimizer = CE_loss(net)\n",
        "    train_accuracy, loss_dic, test_accuracy = train_test_network(trainloader = trainloader, testloader = testloader, net=net, criterion=criterion, optimizer=optimizer, epochs=25)\n",
        "    plot(dictionary = train_accuracy, title = \"Two_conv_with_three_dense_Training_Accuracy\", x = \"Epochs\", y = \"Accuracy\", _print=  \"4. Two conv with three dense layers - training accuracy\")\n",
        "    plot(dictionary = loss_dic, title = \"Two_conv_with_three_dense_Loss\", x = \"Epochs\", y = \"Loss\", _print=  \"4. Two conv with three dense layers - loss\")\n",
        "    plot(dictionary = test_accuracy, title = \"Two_conv_with_three_dense_Testing_Accuracy\", x = \"Epochs\", y = \"Accuracy\", _print=  \"4. Two conv with three dense layers - testing accuracy\")\n",
        "    print('Parameters of the network: %d' % sum(p.numel() for p in net.parameters() if p.requires_grad))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZHEbgGX6UPt9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "########################################################################\n",
        "#  Example Tutorial with batches of different sizes\n",
        "\n",
        "def basic_tutorial_model_batch_sizes():\n",
        "    import examplenetwork\n",
        "    net = examplenetwork.Net()\n",
        "    criterion, optimizer = CE_loss(net)\n",
        "    \n",
        "    ############################################################################\n",
        "    #  two convolutional layers along with maxpooling layers before the fully connected layers on the CIFAR10 data with batch size 1\n",
        "    trainloader, testloader, classes = data_division(batch = 1)\n",
        "\n",
        "    train_accuracy, loss_dic, test_accuracy = train_test_network(trainloader = trainloader, testloader = testloader, net=net, criterion=criterion, optimizer=optimizer, epochs=25)\n",
        "    plot(dictionary = train_accuracy, title = \"Two_conv_with_three_dense_batchsize1_Training_Accuracy\", x = \"Epochs\", y = \"Accuracy\", _print=  \"5. Two conv with three dense layers with 1 sample per batch - training accuracy\")\n",
        "    plot(dictionary = loss_dic, title = \"Two_conv_with_three_dense_batchsize1_Loss\", x = \"Epochs\", y = \"Loss\", _print=  \"5. Two conv with three dense layers with 1 sample per batch - loss\")\n",
        "    plot(dictionary = test_accuracy, title = \"Two_conv_with_three_dense_batchsize1_Testing_Accuracy\", x = \"Epochs\", y = \"Accuracy\", _print=  \"5. Two conv with three dense layers with 1 sample per batch - testing accuracy\")\n",
        "    print('Parameters of the network: %d' % sum(p.numel() for p in net.parameters() if p.requires_grad))\n",
        "    \n",
        "    \n",
        "    ############################################################################\n",
        "    #  two convolutional layers along with maxpooling layers before the fully connected layers on the CIFAR10 data with batch size 4\n",
        "    trainloader, testloader, classes = data_division(batch = 4)\n",
        "\n",
        "    train_accuracy, loss_dic, test_accuracy = train_test_network(trainloader = trainloader, testloader = testloader, net=net, criterion=criterion, optimizer=optimizer, epochs=25)\n",
        "    plot(dictionary = train_accuracy, title = \"Two_conv_with_three_dense_batchsize4_Training_Accuracy\", x = \"Epochs\", y = \"Accuracy\", _print=  \"5. Two conv with three dense layers with 4 sample per batch - training accuracy\")\n",
        "    plot(dictionary = loss_dic, title = \"Two_conv_with_three_dense_batchsize4_Loss\", x = \"Epochs\", y = \"Loss\", _print=  \"5. Two conv with three dense layers with 4 sample per batch - loss\")\n",
        "    plot(dictionary = test_accuracy, title = \"Two_conv_with_three_dense_batchsize4_Testing_Accuracy\", x = \"Epochs\", y = \"Accuracy\", _print=  \"5. Two conv with three dense layers with 4 sample per batch - testing accuracy\")\n",
        "    print('Parameters of the network: %d' % sum(p.numel() for p in net.parameters() if p.requires_grad))\n",
        "    \n",
        "    ############################################################################\n",
        "    #  two convolutional layers along with maxpooling layers before the fully connected layers on the CIFAR10 data with batch size 1000\n",
        "    trainloader, testloader, classes = data_division(batch = 1000)\n",
        "\n",
        "    train_accuracy, loss_dic, test_accuracy = train_test_network(trainloader = trainloader, testloader = testloader, net=net, criterion=criterion, optimizer=optimizer, epochs=25)\n",
        "    plot(dictionary = train_accuracy, title = \"Two_conv_with_three_dense_batchsize1000_Training_Accuracy\", x = \"Epochs\", y = \"Accuracy\", _print=  \"5. Two conv with three dense layers with 1000 sample per batch - training accuracy\")\n",
        "    plot(dictionary = loss_dic, title = \"Two_conv_with_three_dense_batchsize1000_Loss\", x = \"Epochs\", y = \"Loss\", _print=  \"5. Two conv with three dense layers with 1000 sample per batch - loss\")\n",
        "    plot(dictionary = test_accuracy, title = \"Two_conv_with_three_dense_batchsize1000_Testing_Accuracy\", x = \"Epochs\", y = \"Accuracy\", _print=  \"5. Two conv with three dense layers with 1000 sample per batch - testing accuracy\")\n",
        "    print('Parameters of the network: %d' % sum(p.numel() for p in net.parameters() if p.requires_grad))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p_W1NJwOUZ1l",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "############################################################################\n",
        "#  Example Tutorial with different learning rates\n",
        "\n",
        "def basic_tutorial_model_learning_rates():\n",
        "    trainloader, testloader, classes = data_division(batch = 4)\n",
        "    \n",
        "    import examplenetwork\n",
        "    net = examplenetwork.Net()\n",
        "    ############################################################################\n",
        "    # two convolutional layers along with maxpooling layers before the fully connected layers on the CIFAR10 data with learning rate 10\n",
        "    criterion, optimizer = CE_loss(net, lr = 10)\n",
        "    train_accuracy, loss_dic, test_accuracy = train_test_network(trainloader = trainloader, testloader = testloader, net=net, criterion=criterion, optimizer=optimizer, epochs=25)\n",
        "    plot(dictionary = train_accuracy, title = \"Two_conv_with_three_dense_learningrate10_Training_Accuracy\", x = \"Epochs\", y = \"Accuracy\", _print=  \"6. Two conv with three dense layers with a learning rate of 10 - training accuracy\")\n",
        "    plot(dictionary = loss_dic, title = \"Two_conv_with_three_dense_learningrate10_Loss\", x = \"Epochs\", y = \"Loss\", _print=  \"6. Two conv with three dense layers with a learning rate of 10 - loss\")\n",
        "    plot(dictionary = test_accuracy, title = \"Two_conv_with_three_dense_learningrate10_Testing_Accuracy\", x = \"Epochs\", y = \"Accuracy\", _print=  \"6. Two conv with three dense layers with a learning rate of 10 - testing accuracy\")\n",
        "    print('Parameters of the network: %d' % sum(p.numel() for p in net.parameters() if p.requires_grad))\n",
        "    \n",
        "    ############################################################################\n",
        "    # two convolutional layers along with maxpooling layers before the fully connected layers on the CIFAR10 data with learning rate 0.1\n",
        "    criterion, optimizer = CE_loss(net, lr = 0.1)\n",
        "    train_accuracy, loss_dic, test_accuracy = train_test_network(trainloader = trainloader, testloader = testloader, net=net, criterion=criterion, optimizer=optimizer, epochs=25)\n",
        "    plot(dictionary = train_accuracy, title = \"Two_conv_with_three_dense_learningratepoint1_Training_Accuracy\", x = \"Epochs\", y = \"Accuracy\", _print=  \"6. Two conv with three dense layers with a learning rate of 0.1 - training accuracy\")\n",
        "    plot(dictionary = loss_dic, title = \"Two_conv_with_three_dense_learningratepoint1_Loss\", x = \"Epochs\", y = \"Loss\", _print=  \"6. Two conv with three dense layers with a learning rate of 0.1 - loss\")\n",
        "    plot(dictionary = test_accuracy, title = \"Two_conv_with_three_dense_learningratepoint1_Testing_Accuracy\", x = \"Epochs\", y = \"Accuracy\", _print=  \"6. Two conv with three dense layers with a learning rate of 0.1 - testing accuracy\")\n",
        "    print('Parameters of the network: %d' % sum(p.numel() for p in net.parameters() if p.requires_grad))\n",
        "    \n",
        "    ############################################################################\n",
        "    # two convolutional layers along with maxpooling layers before the fully connected layers on the CIFAR10 data with learning rate 0.01\n",
        "    criterion, optimizer = CE_loss(net, lr = 0.01)\n",
        "    train_accuracy, loss_dic, test_accuracy = train_test_network(trainloader = trainloader, testloader = testloader, net=net, criterion=criterion, optimizer=optimizer, epochs=25)\n",
        "    plot(dictionary = train_accuracy, title = \"Two_conv_with_three_dense_learningratepoint01_Training_Accuracy\", x = \"Epochs\", y = \"Accuracy\", _print=  \"6. Two conv with three dense layers with a learning rate of 0.01 - training accuracy\")\n",
        "    plot(dictionary = loss_dic, title = \"Two_conv_with_three_dense_learningratepoint01_Loss\", x = \"Epochs\", y = \"Loss\", _print=  \"6. Two conv with three dense layers with a learning rate of 0.01 - loss\")\n",
        "    plot(dictionary = test_accuracy, title = \"Two_conv_with_three_dense_learningratepoint01_Testing_Accuracy\", x = \"Epochs\", y = \"Accuracy\", _print=  \"6. Two conv with three dense layers with a learning rate of 0.01 - testing accuracy\")\n",
        "    print('Parameters of the network: %d' % sum(p.numel() for p in net.parameters() if p.requires_grad))\n",
        "    \n",
        "    \n",
        "    ############################################################################\n",
        "    # two convolutional layers along with maxpooling layers before the fully connected layers on the CIFAR10 data with learning rate 0.0001\n",
        "    criterion, optimizer = CE_loss(net, lr = 0.0001)\n",
        "    train_accuracy, loss_dic, test_accuracy = train_test_network(trainloader = trainloader, testloader = testloader, net=net, criterion=criterion, optimizer=optimizer, epochs=50)\n",
        "    plot(dictionary = train_accuracy, title = \"Two_conv_with_three_dense_learningratepoint0001_Training_Accuracy\", x = \"Epochs\", y = \"Accuracy\", _print=  \"6. Two conv with three dense layers with a learning rate of 0.0001 - training accuracy\")\n",
        "    plot(dictionary = loss_dic, title = \"Two_conv_with_three_dense_learningratepoint0001_Loss\", x = \"Epochs\", y = \"Loss\", _print=  \"6. Two conv with three dense layers with a learning rate of 0.0001 - loss\")\n",
        "    plot(dictionary = test_accuracy, title = \"Two_conv_with_three_dense_learningratepoint0001_Testing_Accuracy\", x = \"Epochs\", y = \"Accuracy\", _print=  \"6. Two conv with three dense layers with a learning rate of 0.0001 - testing accuracy\")\n",
        "    print('Parameters of the network: %d' % sum(p.numel() for p in net.parameters() if p.requires_grad))\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dygQTMI9Ubyg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "################################################################################\n",
        "#  Example Tutorial using augmented training data\n",
        "\n",
        "def basic_tutorial_model_augmented_data():\n",
        "    trainloader, testloader, classes = data_division(batch = 4, augment = True)\n",
        "    \n",
        "    import examplenetwork\n",
        "    net = examplenetwork.Net()\n",
        "    criterion, optimizer = CE_loss(net)\n",
        "    train_accuracy, loss_dic, test_accuracy = train_test_network(trainloader = trainloader, testloader = testloader, net=net, criterion=criterion, optimizer=optimizer, epochs=25)\n",
        "    plot(dictionary = train_accuracy, title = \"Two_conv_with_three_dense_AugmentedData_Training_Accuracy\", x = \"Epochs\", y = \"Accuracy\", _print=  \"7. Two conv with three dense layers with Augmented Data - training accuracy\")\n",
        "    plot(dictionary = loss_dic, title = \"Two_conv_with_three_dense_AugmentedData_Loss\", x = \"Epochs\", y = \"Loss\", _print=  \"7. Two conv with three dense layers with Augmented Data - loss\")\n",
        "    plot(dictionary = test_accuracy, title = \"Two_conv_with_three_dense_AugmentedData_Testing_Accuracy\", x = \"Epochs\", y = \"Accuracy\", _print=  \"7. Two conv with three dense layers with Augmented Data - testing accuracy\")\n",
        "    print('Parameters of the network: %d' % sum(p.numel() for p in net.parameters() if p.requires_grad))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4ipsNfGCUftI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "##########################################################################\n",
        "#  Example Tutorial with Mean Squared Error loss function\n",
        "\n",
        "def basic_tutorial_model_MSELoss():\n",
        "    trainloader, testloader, classes = data_division(batch = 10, augment = False)\n",
        "    \n",
        "    import examplenetwork\n",
        "    net = examplenetwork.Net()\n",
        "    criterion, optimizer = MSE_loss(net)\n",
        "    #train_accuracy, loss_dic, test_accuracy = train_test_network(trainloader = trainloader, testloader = testloader, net=net, criterion=criterion, optimizer=optimizer, epochs=25)\n",
        "    train_accuracy, loss_dic, test_accuracy = train_test_networkMSE(trainloader = trainloader, testloader = testloader, net=net, criterion=criterion, optimizer = optimizer, epochs = 25, onehotencoding = True)\n",
        "    plot(dictionary = train_accuracy, title = \"Two_conv_with_three_dense_MSELoss_Training_Accuracy\", x = \"Epochs\", y = \"Accuracy\", _print=  \"8. Two conv with three dense layers with MSELoss - training accuracy\")\n",
        "    plot(dictionary = loss_dic, title = \"Two_conv_with_three_dense_MSELoss_Loss\", x = \"Epochs\", y = \"Loss\", _print=  \"8. Two conv with three dense layers with MSELoss - loss\")\n",
        "    plot(dictionary = test_accuracy, title = \"Two_conv_with_three_dense_MSELoss_Testing_Accuracy\", x = \"Epochs\", y = \"Accuracy\", _print=  \"8. Two conv with three dense layers with MSELoss - testing accuracy\")\n",
        "    print('Parameters of the network: %d' % sum(p.numel() for p in net.parameters() if p.requires_grad))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q1FviydPUkHJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def onehot(y,batch_size,nb_digits):\n",
        "    y_onehot = torch.FloatTensor(batch_size, nb_digits).zero_()\n",
        "    y_onehot.scatter_(1, y, 1)\n",
        "    return y_onehot"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mYm4iu8DUoDq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def main():\n",
        "    \n",
        "    #single_fully_connected_model() #2\n",
        "    #multiple_fully_connected_model() #3\n",
        "    \n",
        "    basic_tutorial_model() #1, 4\n",
        "    #basic_tutorial_model_batch_sizes() #5\n",
        "    #basic_tutorial_model_learning_rates() #6'''\n",
        "    #basic_tutorial_model_augmented_data() #7\n",
        "    #basic_tutorial_model_MSELoss() #8"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iqCjlrKwUpxP",
        "colab_type": "code",
        "outputId": "b516023f-3981-4cdc-ccba-3d564cd9824b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "if __name__ == '__main__':\n",
        "    main()"
      ],
      "execution_count": 96,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Files already downloaded and verified\n",
            "Files already downloaded and verified\n",
            "[1,  2000] loss: 2.269\n",
            "[1,  4000] loss: 1.927\n",
            "[1,  6000] loss: 1.714\n",
            "[1,  8000] loss: 1.602\n",
            "[1, 10000] loss: 1.542\n",
            "[1, 12000] loss: 1.504\n",
            "[2,  2000] loss: 1.432\n",
            "[2,  4000] loss: 1.402\n",
            "[2,  6000] loss: 1.338\n",
            "[2,  8000] loss: 1.340\n",
            "[2, 10000] loss: 1.320\n",
            "[2, 12000] loss: 1.311\n",
            "[3,  2000] loss: 1.225\n",
            "[3,  4000] loss: 1.201\n",
            "[3,  6000] loss: 1.231\n",
            "[3,  8000] loss: 1.189\n",
            "[3, 10000] loss: 1.206\n",
            "[3, 12000] loss: 1.181\n",
            "[4,  2000] loss: 1.081\n",
            "[4,  4000] loss: 1.135\n",
            "[4,  6000] loss: 1.125\n",
            "[4,  8000] loss: 1.076\n",
            "[4, 10000] loss: 1.101\n",
            "[4, 12000] loss: 1.098\n",
            "[5,  2000] loss: 0.997\n",
            "[5,  4000] loss: 1.016\n",
            "[5,  6000] loss: 1.032\n",
            "[5,  8000] loss: 1.043\n",
            "[5, 10000] loss: 1.022\n",
            "[5, 12000] loss: 1.032\n",
            "[6,  2000] loss: 0.925\n",
            "[6,  4000] loss: 0.974\n",
            "[6,  6000] loss: 0.976\n",
            "[6,  8000] loss: 0.968\n",
            "[6, 10000] loss: 0.982\n",
            "[6, 12000] loss: 0.970\n",
            "[7,  2000] loss: 0.912\n",
            "[7,  4000] loss: 0.905\n",
            "[7,  6000] loss: 0.901\n",
            "[7,  8000] loss: 0.928\n",
            "[7, 10000] loss: 0.945\n",
            "[7, 12000] loss: 0.931\n",
            "[8,  2000] loss: 0.846\n",
            "[8,  4000] loss: 0.855\n",
            "[8,  6000] loss: 0.872\n",
            "[8,  8000] loss: 0.896\n",
            "[8, 10000] loss: 0.915\n",
            "[8, 12000] loss: 0.887\n",
            "[9,  2000] loss: 0.805\n",
            "[9,  4000] loss: 0.833\n",
            "[9,  6000] loss: 0.860\n",
            "[9,  8000] loss: 0.855\n",
            "[9, 10000] loss: 0.870\n",
            "[9, 12000] loss: 0.857\n",
            "[10,  2000] loss: 0.760\n",
            "[10,  4000] loss: 0.796\n",
            "[10,  6000] loss: 0.818\n",
            "[10,  8000] loss: 0.828\n",
            "[10, 10000] loss: 0.834\n",
            "[10, 12000] loss: 0.861\n",
            "[11,  2000] loss: 0.725\n",
            "[11,  4000] loss: 0.782\n",
            "[11,  6000] loss: 0.783\n",
            "[11,  8000] loss: 0.797\n",
            "[11, 10000] loss: 0.810\n",
            "[11, 12000] loss: 0.854\n",
            "[12,  2000] loss: 0.719\n",
            "[12,  4000] loss: 0.747\n",
            "[12,  6000] loss: 0.778\n",
            "[12,  8000] loss: 0.765\n",
            "[12, 10000] loss: 0.800\n",
            "[12, 12000] loss: 0.799\n",
            "[13,  2000] loss: 0.687\n",
            "[13,  4000] loss: 0.684\n",
            "[13,  6000] loss: 0.753\n",
            "[13,  8000] loss: 0.769\n",
            "[13, 10000] loss: 0.774\n",
            "[13, 12000] loss: 0.795\n",
            "[14,  2000] loss: 0.678\n",
            "[14,  4000] loss: 0.698\n",
            "[14,  6000] loss: 0.747\n",
            "[14,  8000] loss: 0.738\n",
            "[14, 10000] loss: 0.728\n",
            "[14, 12000] loss: 0.767\n",
            "[15,  2000] loss: 0.658\n",
            "[15,  4000] loss: 0.691\n",
            "[15,  6000] loss: 0.723\n",
            "[15,  8000] loss: 0.722\n",
            "[15, 10000] loss: 0.770\n",
            "[15, 12000] loss: 0.741\n",
            "[16,  2000] loss: 0.649\n",
            "[16,  4000] loss: 0.682\n",
            "[16,  6000] loss: 0.681\n",
            "[16,  8000] loss: 0.708\n",
            "[16, 10000] loss: 0.743\n",
            "[16, 12000] loss: 0.730\n",
            "[17,  2000] loss: 0.636\n",
            "[17,  4000] loss: 0.657\n",
            "[17,  6000] loss: 0.698\n",
            "[17,  8000] loss: 0.697\n",
            "[17, 10000] loss: 0.717\n",
            "[17, 12000] loss: 0.726\n",
            "[18,  2000] loss: 0.600\n",
            "[18,  4000] loss: 0.665\n",
            "[18,  6000] loss: 0.672\n",
            "[18,  8000] loss: 0.692\n",
            "[18, 10000] loss: 0.704\n",
            "[18, 12000] loss: 0.717\n",
            "[19,  2000] loss: 0.586\n",
            "[19,  4000] loss: 0.629\n",
            "[19,  6000] loss: 0.659\n",
            "[19,  8000] loss: 0.674\n",
            "[19, 10000] loss: 0.700\n",
            "[19, 12000] loss: 0.722\n",
            "[20,  2000] loss: 0.587\n",
            "[20,  4000] loss: 0.631\n",
            "[20,  6000] loss: 0.644\n",
            "[20,  8000] loss: 0.681\n",
            "[20, 10000] loss: 0.689\n",
            "[20, 12000] loss: 0.741\n",
            "[21,  2000] loss: 0.577\n",
            "[21,  4000] loss: 0.618\n",
            "[21,  6000] loss: 0.635\n",
            "[21,  8000] loss: 0.657\n",
            "[21, 10000] loss: 0.680\n",
            "[21, 12000] loss: 0.710\n",
            "[22,  2000] loss: 0.592\n",
            "[22,  4000] loss: 0.620\n",
            "[22,  6000] loss: 0.641\n",
            "[22,  8000] loss: 0.643\n",
            "[22, 10000] loss: 0.698\n",
            "[22, 12000] loss: 0.687\n",
            "[23,  2000] loss: 0.555\n",
            "[23,  4000] loss: 0.619\n",
            "[23,  6000] loss: 0.648\n",
            "[23,  8000] loss: 0.649\n",
            "[23, 10000] loss: 0.669\n",
            "[23, 12000] loss: 0.686\n",
            "[24,  2000] loss: 0.537\n",
            "[24,  4000] loss: 0.594\n",
            "[24,  6000] loss: 0.648\n",
            "[24,  8000] loss: 0.645\n",
            "[24, 10000] loss: 0.675\n",
            "[24, 12000] loss: 0.677\n",
            "[25,  2000] loss: 0.568\n",
            "[25,  4000] loss: 0.585\n",
            "[25,  6000] loss: 0.628\n",
            "[25,  8000] loss: 0.635\n",
            "[25, 10000] loss: 0.660\n",
            "[25, 12000] loss: 0.670\n",
            "Finished Training\n",
            "4. Two conv with three dense layers - training accuracy\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAX4AAAEWCAYAAABhffzLAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjEsIGh0\ndHA6Ly9tYXRwbG90bGliLm9yZy8QZhcZAAAgAElEQVR4nO3de3wcZfn//9eVpGnTY3pIS89nCthC\nC6EciiCgVkSxgCCoHBStKCieKvD54Uf9iVIBQRE/KKBYEERAKIhykkKLoEDPLZSej2nSJm3TNm3a\nnK7vHzMpS7KbbNJsNsm8n4/HPrIzszNzzU722nvvuee+zd0REZHoyEh3ACIi0rqU+EVEIkaJX0Qk\nYpT4RUQiRolfRCRilPhFRCJGiV+axMw6m1mZmQ1q4DVFZnZaC+xrppndf7jbaWktdXxtnZltMLMT\nW/q1kn5K/ECYyGofNWZWHjP9hXTH15a4+0F37+7uWwHM7FEzu+lwt2tmnzCzNYcfYTSZ2dqY/9lq\nMzsQM/3d5mzT3Ue4+9st/drDYWbjzczN7LZU76sjU+IHwkTW3d27A5uAT8fMezjd8UnjzCwr3TGk\nk7uPjvkffhv4Ssz/8B11X9+O368rgJ3AF8wsszV33I7fs3qU+BthZt3D0lPPcPqnZnbQzHLC6dvM\nbGb4vI+ZPWJmxWa23sx+YGaWxD6+YWbvmdleM1tmZhPC+RPM7DUzKzWzpWZ2Tsw6j5rZr8zshXC9\n181seLjsATO7uc4+XjCzbzQQw9fN7PGY6c1m9lDM9HYzO8rMuoQlriFm9i3gQuCHYcny8ZhNnmhm\ny81st5k9bGbZDey7L/AUMCqmlNo3XJxjZn8Jj3GpmU2MWa/IzL5vZu8Ae8J5Q83saTMrMbN1ZnZ1\nzOszzeyH4fySMK7cRHHFrHeVmW0Kz+uMOssSbjN8v6rM7EtmtqXu+mY2xcwWmdme8FhuiVn2YTN7\nMzz3C81sSmNxNnIM15rZS2b2OzPbBXzfzI4xs3lmtjM8vw+YWfeYdUrM7OTw+e1m9qCZ/TU8F0tq\n/0+b8dpTwv/zvWb2UHi+bkjiGDKBLwDfB7oBH6uzfJKZvWpmu8ys0My+Hc7vZGY/seAzucfM3jKz\nPAt+PRyos435ZnbJYbxno8zs7+H7UWxmt1qQQ/aa2aiY1w03s30W5pVW5+56xDyADcBH68x7Czg3\nfD4PWAucGbPsnPD5Y8DjQHdgDLAe+EIj+7sM2AhMAgwYBwwBuhD8+vge0AmYCpQBI8P1HgW2A8eH\ny58A/hQu+ziwJmYf/YFyoF8DcRwDbA+fjwpjXx+zrCh83gVwYEhMHDfV2VYR8DowAMgD1gBXNvI+\nfCI25nDeTGA/wQc8E7gTeLXOft4GBgE54WuWAdcD2cCR4Xt4Rvj664HXwtd3Af4EPNBIXJOAvcAp\nQGfgt0AVcFpj2wSOCt+r34bLTgQqgFHh8kXAReHzHsBJ4fMRwA7gowSFs08CxUDvJP+H/wt8sc68\na8O4vxS+Tznhef1I+P8zkOB/+eaYdUqAk8PntwP7gLPC9X8D/KuprwW6AtuArwBZwBeBSuCGJI7r\nnPBcdAUeAP4Ss6xv+J5dHZ77XsCJ4bKfAPMJ/q8zgBPC5eOBA3X2MR+4pDnvWbjfVcDNYYxdgVPD\nZQ8CP4zZz/8XG3+r57l07bitPoif+G8DbiX44BcSlDh+HH5YDwA9w2XVtR/qcL3rgOcb2d9c4Gtx\n5n+M4AvBYuY9VfsBIUi4d8csuwBYHD7PJEiKk8PpbwL/TOLYt4f/2FcCdwFLCZLQ14HHwtckm/g/\nGzN9F/CrRvadKPE/GzN9PFBaZz+fj5k+A1hdZxs/Ae4Jn68HpsQsG0nwxWINxPVzwi/UcLoXUMP7\niT/hNnk/8feLWb4UmBY+fytMAH3r7PNHwH1x/k8+l+T/cKLE/24j630ReC1mum4ynx2zbDJQ0tTX\nEnyJraqz38Ukl/gfBf4c8/nYD/QMp78aG3ud9QqAs+PMTybxJ/2e8f5nNiPO684G3ouZXgF8Mpnz\nmYqHqnqSM5fgW/4kgn+MOQRJZgqwzN33AEcQlCY2xay3ERjcyLaHEvyCqGsQsMnD/5IE2yuKeb6f\n4JcG7l5N8Ovj0nDZ54FkrlXMIzjO0wmO+VWC4zwjnG6KuLE1Q2Pb2RzzfDgwIqweKTWzUuC7wBFm\nZgTv9T9jli0iOGd9SWxQ7D7cfTewGyDJbVa7e0mCY7gCOBZYFVbrTI05ji/WOY78MJbDEfteYUF1\n3RNmttXM9gC/A/o1sH5Tzmmi1w4CtjQUVzxm1gv4DO//H88hOA8Xh9NxP0dh9dDAeMuS1JT3bCjB\nr+SaONt5BehqZieaWT7QB3ixmTEdNiX+5PwbOA44lyABLiYozX2c9xNiEUFJcFjMesMIShsN2QyM\njjN/a51tJbu9Wn8BLjazMcAEYHYS69R+wX2Y4EtgLo0n/pbq3rW524ldbzNBqSo35tHD3c8Pv0AL\ngLPqLO9SJzHXVUjwgQYOJaBeAIexTcL1V7j75wiq4u4CnrTgWshm4P462+zm7nc27a2pv8s6078k\nSJ7HuHtPgmqSRq9JHaZCgqrMWEPjvbCOzxH82pxlZkUE73sfgi9PSPA5CgtBhfGWEVRHdbIPXrQd\nUHcTdaYbes82AyPDAkHdOGqAhwh+IVxGUM1TFf9QU0+JPwnuXgq8Q1DlMTc8ifMJ6innhq85SFAV\n83Mz62Zmowmqev7cyObvB24ws+MscKSZDSGoN84ws2+bWZaZfYzgi+axJGP+D3AQuAf4u7vvS2K1\nuQRVLhXuXhxOX0hQn/lOgnW2EdSdHq5tQP/YC2XN8G+A8D3rEr5vx5rZ8eHy3wEzzWxo+Lr+Zvbp\nRrb5GHCBmZ1kZp0J6m9jS3TN2Sbhay83s75hctpNkGQcmAVcZGZnW3DxOCd8fkRS70LyehDUme8x\nsxHAd1p4+/G8AuSa2ZfD8/N54ENJrHcFwbWCY4GJ4eNsYEp40fRJ4Bgzm25m2WbWKyxZQ/AZu8XM\nRphZhpkdH36BbwF2AZ8P3+dvEvxyb0hD79lcgs/cT8Jz1tXMTo1Z/iDBF9gl4fO0UeJP3lyCb/aF\nMdPdCJNN6Gvh340EP0Xvp5EqFnd/CLiD4OLs3vBvrrsfAD4FfJbgotUdBHW865oQ818ILhA+kuTr\nlxFcaJsXxlZCUIp5rU6VU6x7CVrwlJrZo02Ira4lwDPAxnBbfZq6AXevJKhDPpXgHBQTfPHVfpnc\nCvwLmGNme4E3CK4bNLTNRQQX2J8gSBSbCOqzazV5mzE+BawM17sFuNjdK8NzfCHB9YmS8Fiuo+U/\nrzcBZxK0iHqCoGFCSrn7fuB8giq4XQTn618ECTMuMxsLnAz82t2LYh7/Jvj8Xe7uOwjq2L9IcN5X\nEPwfQPBl/SLBZ7YU+D8gO/x/+Wq4vJigtL+kkUNI+J65ewXBBeh8gl8kG4DzYpavDOeVuPtC0sgS\nf55FRFLPzJYDP3H3lH/xpJuZPQYsdPeZ6YxDJX4RaVVmdpYF7eg7WXBvyTDg5XTHlWpmdiRBVeqf\n0hyKEn9rMLM/2Qe7hah9/KqV4zgyQRxlZta/Ffb/kwT7firV+24krqsSxLUgnXHVZe/3kxTv0Z76\nyTmW4JrRLoKqlvPdfaeZ/SzBsbX7XwJmdgewAPiRuxc19vqUx6OqHhGRaFGJX0QkYtpFp0P9+vXz\nESNGpDsMEZF2ZcGCBSXunld3frtI/CNGjGD+/PnpDkNEpF0xs43x5quqR0QkYpT4RUQiRolfRCRi\nlPhFRCImZYnfzMaZ2eKYx56w86w+Foxqszr82ztVMYiISH0pS/zuvtLdJ7r7RIIRb/YTDiQCvOzu\nYwlu0250yDURkaiZvaiAKTPnMPKGfzBl5hxmL0q2R/bGtVZVz9nAWnffSDCYwqxw/ixgWivFICLS\nLsxeVMCNTy6joLQcBwpKy7nxyWUtlvxbK/FfQtBFMMAAdy8MnxdRf+ADAMJ+teeb2fzi4uLWiFFE\nJCWaUnrfd7CKn/1zBeWV1R+YX15ZzW0vrGyReFJ+A5cFIwqdB9xYd5m7u5nF7SzI3e8l6Oud/Px8\ndSgkIu1Sbem9NpEHpfel7DlQwdj+PVlTXMba7WWsDf9u3X0g4ba2lpa3SEytcefuOQT9T28Lp7eZ\n2UB3LzSzgQQDfIuItAuzFxVw2wsr2VpazqDcHGZMHce0SfGH1q6ucW55Ll7pvYb/ffrdQ9PdsjMZ\n3b87J43qy+i8bvzx9fXs3FdZb3uDcnNa5BhaI/FfyvvVPBCMsnQFMDP8+3QrxCAictjil96XUV1T\nw3FDe7Nm+17WbC9j9fYyVm8LSvEHq+KNvR546KrJjOnfnSN6dsFihuod0rvrB/YDkNMpkxlTx7XI\ncaQ08ZtZN4Lh0L4WM3sm8JiZXUUwpNzFqYxBRKSl3PrCe3Hr3r/3+NIPzBucm8PYAd2ZMqYvj8/f\nQml5/dL74NwcPjy2Xv9pAId+QST7y6KpUpr4wwG++9aZt4OglY+ISFolqrapqXEKSstZWbSXldv2\nsmrbXlYW7WVraeL69zsuPo6x/XswKq8b3Tq/n1o/NKhXs0rv0yYNbrFEX1e76J1TRKSlxau2+d7j\nS7jjpZXsKKtgX8X7iXpwbg7jjujBll3llB2sqretwbk5XHD8kLj7SXXpvTmU+EWkw2jowmt5RfWh\nkvt7RXt5+M2N9erfq2ucoj0H+fzkYYw7ogdHDujB2AHd6dml06Htt7XSe3O0i6EX8/PzXf3xi0hD\n4iXlrAzjmIE92Huwmg079lGb7rp0yuBAZfyLrgasn3lug/tpS6X3hpjZAnfPrztfJX4RaZOSSbBV\n1TWsKS5jecEefvTM8noXXqtqnHcK9/Kxowdw3nGDOHpgD8Yd0ZNhfbpy+q2vUBCnXXxjTSbbWum9\nOZT4RaTNiVf/fsOTS9m8az953TuzfOtulhXs4b3CPQ02lwSoqXF+d9kJ9ebPmDoupU0m2zIlfhFp\nc259vn6zyQOVNfzyxVUA9OiSxfhBvbj8lOGMH9yL8YN7cdkf3ozb6iZRCb4tXnRtLUr8IpJyDVXb\nVNc464rLWLJlN0u3lLJky+4Guy2YO+MjDOvT9QM3PAH8YOpRTS7Bd4Rqm+ZQ4heRlIpXbTPjiSU8\nvXgL+ytqWF6w+1DTye6dsxg/uCfdO2clbDY5vG+3uPuJcgm+qZT4RSRl9h2s4uZ/vFuv2qay2nll\nZQkTh+by2ROGcOyQXI4b2otR/bqTkWEdptlkW6XELyJNFq/q5jMTB7FlVzkLNu5i4aZdLNi4i/eK\n9lJdE7/JuAGzr5kSd5lK76mldvwi0iTxSuMZBl2zMyk7GMzrlp3JxGG5nDCsNw+/uYkd+yrqbWdw\nbg6v33BWq8UdRWrHLyKHpexgFQs27uKm2fXby9c4VNfAT6eN54RhvRl3RA8yM4KLr6Pyuke22WRb\npcQvEnGJWtzs3FfB2xt28tb64PHO1t0kqLUB4EBlNZedPLzefFXbtD2q6hGJsHjVNpkZRl73bIr2\nHASgc1YGk4blMnlEHyaP7MuMJ5ZQGKe5papu2h5V9YjIB+zcV8FP/v5OvWqb6hpn1/5KZkwdx0kj\n+zBhSC86Z2UeWn79J5reXl7aFiV+kQ6koRulyg5W8fb6nby+poTX1+5gReGehNupqKrhmjPHxF2m\nqpv2T1U9Ih1EvGqb7KwMzjyyHyX7KlmyuZSqGic7K4MThvVmypi+zHpjI8VlB+ttS9U2HYOqekQ6\nuNviDAtYUVXDC+9u57ihuUw/fRRTxvTjhOG96dIpqLpJ9diu0jYp8Yu0Y7vLK3l9TQlzVxZTkGBY\nQAOe1o1SEkOJX6QNq1tn//2PHcnoAd2Zu7KYuauKWbS5lOoap0eXrISDi0Shf3lpmpQmfjPLBe4H\nxgMOfBmYCnwVKA5f9j/u/s9UxiHSHsXr3Ow7jy85tPzYIb34xkdGc8aReUwcmsuzSwtVbSNJSXWJ\n/9fA8+7+WTPLBroSJP473f32FO9bpF1yd1YU7uV/n65/hyxA766deOm7Z9Cve+cPzFe1jSQrZYnf\nzHoBpwNXArh7BVBRtw9tkahoqKnlgcpq/rNuB3NWbGfOe9vjDglYq3R/Zb2kX0vVNpKMVJb4RxJU\n5zxgZscBC4DrwmXXmtnlwHzge+6+q+7KZjYdmA4wbNiwFIYpknpxhxL821L+u24HO/dV8O81Jeyv\nqCanUyanje3Ht84ew50vraZoT/IjSokkK2Xt+M0sH/gvMMXd3zSzXwN7gLuBEoI6/58CA939yw1t\nS+34pb2bMnNOwlL8oF5dOOvo/px99ABOGdX3UFPLRH3S33LBBJXqJSnpaMe/Bdji7m+G008AN7j7\ntpig7gOeTWEMImnl7qzctjdh0jfg9RvOqjeMIKjOXlInZYnf3YvMbLOZjXP3lcDZwLtmNtDdC8OX\nnQ8sT1UMIung7qzaVsY/lhXyj6VbWVu8L+FrB+XmxE36tVRnL6mQ6lY93wQeDlv0rAO+BNxlZhMJ\nqno2AF9LcQwiLS7ehdpjBvXk2aWF/HNZIWu2l5FhMHlkH66cMhJ355Z/vqemltImpDTxu/tioG79\n0mWp3KdIqsVtX//XxThgBieN7MMVp3yIqeOPoH+PLofW69mlk6ptpE3QnbsiTTTzufp94jjQK6cT\nL3339A8k+1iqtpG2QolfJAnlFdW8+G4Rf1tYELeJJcCe8sqESV+kLVHiFyF+nf15xw3iv+t28OSi\nAp5bVsi+imoG5+bQo3MWew9W1duG2tdLe6HEL5EXr87++48v4cfPLKe0vIrunbM499iBXHD8ECaP\n6MMzS7aqTxxp15T4JfJue2FlvTr7qhqnvLKGuy6dxMeOHkBO9vtDD6p9vbR3SvwSWe7Om+t3Jry5\nqqKqhvOOGxR3mS7USnumxC+Rs6PsIH9buIVH397MuuJ9GEGrnLpUZy8dlRK/dDiJLtS+sXYHf3l7\nEy++U0RltZM/vDfXXDSG6hrnR8+8ozp7iQwlfulQEl2o/f+ffYed+yrJ7dqJy04ewaWThzJ2QI9D\n62VnZajOXiJDiV86lEQXassOVvPrSyYy9UNHHOr9Mpbq7CVKlPilw9hfUZXwQm1lVQ2fmajELgJK\n/NIBFJSW8+B/NvDoW5sTvkYXakXep8Qv7ZK7s3DTLv74+gaeX16Eu/OJ8Ucwpn937pu3jvLKmkOv\n1YVakQ9S4pc2rW4Lne98dCxZmRk88Pp6lmzZTc8uWXzltJFcdspwhvTuCsCoft11oVakASkberEl\naejFaIo39GCtUXnd+NKUkVx4/GC6Zqv8IhJPOoZeFDks8VroAPTtls2/vnMGGRmJR64SkcQy0h2A\nSDxFuw8kbKGzc1+Fkr7IYVCJX9qUot0HuOfVNfxFLXREUkaJX9qEot0H+N3ctTzy1iZqapyL8ocw\npn93bn9hlbpSEGlhKU38ZpYL3A+MJ+gH68vASuCvwAiCwdYvdvddqYxD2o66rXSmnz6S9SX7DyX8\nz54whGvOHMPQPkELnb7dOquFjkgLS2mrHjObBbzm7vebWTbQFfgfYKe7zzSzG4De7n59Q9tRq56O\nIVErHQMuzh/KNWeOYVjfrukJTqQDStSqJ2UXd82sF3A68AcAd69w91LgM8Cs8GWzgGmpikHalkSt\ndPr37MwvPnuskr5IK0llq56RQDHwgJktMrP7zawbMMDdC8PXFAED4q1sZtPNbL6ZzS8uLk5hmNIa\nDlZVJ2yls33PwVaORiTaUpn4s4DjgXvcfRKwD7gh9gUe1DPFrWty93vdPd/d8/Py8lIYpqSSu/Ps\n0q189I65CV+jVjoirSuViX8LsMXd3wynnyD4IthmZgMBwr/bUxiDpNHCTbu48J43uPaRRXTLzuLq\nM0aRU6dLZLXSEWl9KWvV4+5FZrbZzMa5+0rgbODd8HEFMDP8+3SqYpD02LxzP7e+sJK/L9lKXo/O\n/OLCCXz2hKFkZhhHHdFTrXRE0izVrXomEjTnzAbWAV8i+JXxGDAM2EjQnHNnQ9tRq562qW7TzGvP\nGs3GHeX88fX1ZBhM//AovnbGaLp11u0iIumQqFWPOmmTZmmoA7ULjh/MjKnjGNhLdfci6aRO2qRF\nJWqamdejM3dcPDENEYlIstRJmzTL1gRNM0v2qmmmSFunEr80ibvz9OKtmEG8WkI1zRRp+5T4JWkF\npeXc9NQyXllZzLA+OWzbc5CDVRriUKS9UeKXRtXUOA/9dyO3Pv8eNQ7/+6ljuOLUEfx9yVY1zRRp\nh5T4pUFrtu/l+r8tY8HGXXx4bD9+fv6EQz1nTps0WIlepB1S4hcg/qDmW3cf4O45a+jaOZM7Lj6O\n8ycNxkwjX4m0d0r8Uq9NfkFpOTOeWIoDnz5uED/69DH06945vUGKSItR4pe4bfKdYFDz31w6KT1B\niUjKqB2/JGyTv3NfRStHIiKtQYlfyO3aKe58tckX6ZiU+CPsQGU1Nz65jF37K8moc81WbfJFOi7V\n8UfUhpJ9fOPhhbxbuIdvfGQ0Y/K68cuXVqtNvkgEKPFH0HPLCvnBE0vJyDD+eGU+Zx0VjH55wQlD\n0xyZiLQGJf4Iqaiq4ZbnVvDA6xuYODSXuz8/iSG9NcC5SNQo8UfEll37ueaRRSzZXMqXp4zkhnOO\nIjtLl3hEokiJv4OKvRO3T7ds9ldUkZWRwT1fOJ5zJgxMd3gikkaNFvnM7Jtm1rs1gpGWUXsnbkFp\nOQ7s2FfBgaoarvvoWCV9EUmqOecA4G0ze8zMPmHqrKXNi3snrsMDr29IT0Ai0qY0mvjd/SZgLPAH\n4EpgtZn93MxGpzg2aaZEd+Immi8i0ZLU1T0PRmQvCh9VQG/gCTO7taH1zGyDmS0zs8VmNj+c92Mz\nKwjnLTazTx7mMUiMDSX7yEjwo0x34ooIJHFx18yuAy4HSoD7gRnuXmlmGcBq4AeNbOJMdy+pM+9O\nd7+9OQFLYu9u3cPlf3yLzllGtZtGxxKRuJJp1dMHuMDdN8bOdPcaM/tUasKSplqwcSdfeuBtunXO\n4plvnsbygj0aHUtE4kom8T8H7KydMLOewNHu/qa7r2hkXQdeNDMHfu/u94bzrzWzy4H5wPfcfVfd\nFc1sOjAdYNiwYUmEGV1zVxVz9UMLGNCzM3/+ykkM6d2VMf17KNGLSFzJ1PHfA5TFTJeF85Jxmrsf\nD5wDXGNmp4frjgYmAoXAL+Ot6O73unu+u+fn5eUlubvo+eeyQr4y621G9OvG41efqjtxRaRRySR+\nCy/uAkEVD0ne+OXuBeHf7cBTwGR33+bu1eF27gMmNz1sAfjr25u49pGFHDskl0enn0xeD42SJSKN\nSybxrzOzb5lZp/BxHbCusZXMrJuZ9ah9DnwcWG5msXcQnQ8sb07gUXfvvLVc/7dlnDY2j4eumkyv\nnPh96ouI1JVMyf1q4C7gJoI6+5cJ694bMQB4KrzfKwt4xN2fN7OHzGxiuK0NwNeaEXdkuTu3v7iS\n376ylnMnDOTOz01Unzsi0iSNJv6wmuaSpm7Y3dcBx8WZf1lTtxV1sf3udM3OZF9FNZecOJSfnT+B\nzLojqIiINCKZdvxdgKuADwFdaue7+5dTGJeEavvdqe2CYV9FNVkZxkkj+yjpi0izJFNH8BBwBDAV\nmAsMAfamMih5X7x+d6pqnNtfXJWmiESkvUsm8Y9x9x8C+9x9FnAucFJqw5Ja6ndHRFpaMom/Mvxb\nambjgV5A/9SFJLF6dIlfG6d+d0SkuZJp1XNv2B//TcAzQHfghymNSgB4dulW9hyoItOg2t+fr353\nRORwNJj4w47Y9oRdKswDRrVKVML8DTv57mNLyB/em8+dOJRf/Wu1+t0RkRbRYOIPO2L7AfBYK8Uj\nwPqSfXzlwfkMzs3hvsvz6d0tm4vyh6Y7LBHpIJKp4/+XmX3fzIaaWZ/aR8oji6gdZQe58oG3yDDj\ngStPpHe37HSHJCIdTDJ1/J8L/14TM89RtU+LO1BZzVcfnE/R7gM88tWTGdGvW7pDEpEOKJk7d0e2\nRiBRV1PjfOevi1m0uZT/+/zxnDBc49uLSGokc+fu5fHmu/uDLR9OdN3y3AqeW17ETecezTkTBja+\ngohIMyVT1XNizPMuwNnAQkCJv4U8+J8N3Pfaei4/ZThXnaYfWCKSWslU9XwzdtrMcoFHUxZRxPzr\n3W38+Jl3+OjR/fnRpz+EJRgoXUSkpTSnP999gIqlLWDZlt188y+LGD+4F3ddOkmdrolIq0imjv/v\nBK14IPiiOAa162+22C6WzaBnl07cf0U+XbOTGtRMROSwJZNtbo95XgVsdPctKYqnQ6vbxbI7lFdW\n88aaHboTV0RaTTJVPZuAN919rru/DuwwsxEpjaqDitfF8sGqGm57YWWaIhKRKEom8T8O1MRMV4fz\npInUxbKItAXJJP4sd6+onQifqx+BZujfs3Pc+epiWURaUzKJv9jMzqudMLPPACWpC6ljqqlxenXp\nVG++ulgWkdaWzMXdq4GHzezucHoLEPdu3rrMbAPBMI3VQJW754cdvP0VGAFsAC4Ou33u0P785kZW\nbS/jovwhvLFmh7pYFpG0SeYGrrXAyWbWPZwua+I+znT32F8INwAvu/tMM7shnL6+idtsV9aX7OPn\n/1zBGUfmceuFx+omLRFJq0areszs52aW6+5l7l5mZr3N7ObD2OdngFnh81nAtMPYVptXXeN877HF\nZGdm8AslfRFpA5Kp4z/H3UtrJ8JqmU8muX0HXjSzBWY2PZw3wN0Lw+dFwIB4K5rZdDObb2bzi4uL\nk9xd2/P7eWtZuKmUn04bzxG9uqQ7HBGRpOr4M82ss7sfBDCzHCB+85T6TnP3AjPrD7xkZu/FLnR3\nNzOPt6K73wvcC5Cfnx/3NW3disI93PnSKj454QjOO25QusMREQGSS/wPAy+b2QOAAVfyflVNg9y9\nIPy73cyeAiYD28xsoLsXmtlAYHuzIm/jKqpq+O5jS+iVk83N0yaoikdE2oxGq3rc/RfAzcDRwDjg\nBWB4Y+uZWTcz61H7HPg4sBx4BrgifNkVwNPNiryN+/XLq1hRuIeZF0ygj4ZPFJE2JNmewbYR1Ndf\nBKwH/pbEOgOAp8KSbhbwiECaEskAAA3nSURBVLs/b2ZvA4+Z2VXARuDiJkfdxi3ctIt7Xl3LRScM\n4aPHxL2EISKSNgkTv5kdCVwaPkoI2t6bu5+ZzIbdfR1wXJz5OwgGc+mQyiuq+f5jSxjYK4cffvqY\ndIcjIlJPQyX+94DXgE+5+xoAM/tOq0TVjv3i+fdYV7KPR75yEj3j3KkrIpJuDdXxXwAUAq+Y2X1m\ndjbBxV1J4PU1JfzpjQ1ceeoITh3TL93hiIjElTDxu/tsd78EOAp4Bfg20N/M7jGzj7dWgO3FngOV\n/OCJpYzq143rP3FUusMREUkomS4b9gGPAI+YWW+CC7zXAy+mOLZ2oXZErYKwa+Vvf3QsOdmZaY5K\nRCSxJo256+673P1ed++wF2ebonZErYKY/vR/P3cdsxcVpDEqEZGGNWewdQnFG1GrvLJaI2qJSJum\nxH8YNKKWiLRHSvyHIVGnaxpRS0TaMiX+w3D8sNx68zSiloi0dUr8zbS/ooo31u7g6CN6MDg3BwMG\n5+ZwywUTNKKWiLRpyfbVI3U88uYmdu2v5P4rTuSE4b3THY6ISNJU4m+GA5XV/H7eOk4d3VdJX0Ta\nHSX+Znh8/maK9x7k2rPGpDsUEZEmU+JvooqqGn43dx0nDO/NKaP6pjscEZEmU+JvotmLCigoLefa\ns8ZoVC0RaZeU+JugqrqG/3t1DeMH9+QjR+alOxwRkWZR4m+CfywrZMOO/Vx75liV9kWk3VLiT1JN\njXP3nDUcOaA7H9dwiiLSjinxJ+nFd7exensZ15w5howMlfZFpP1KeeI3s0wzW2Rmz4bTfzKz9Wa2\nOHxMTHUMh8vdufuV1Yzo25VPHTso3eGIiByW1rhz9zpgBdAzZt4Md3+iFfbdIl5dVczygj3ceuGx\nZKq0LyLtXEpL/GY2BDgXuD+V+0kld+c3L69mcG6O+uARkQ4h1VU9vwJ+ANTUmf8zM1tqZneaWed4\nK5rZdDObb2bzi4uLUxxmYv9Zt4OFm0q5+oxRZGfpkoiItH8py2Rm9ilgu7svqLPoRoIB3E8E+hCM\n31tPOMRjvrvn5+Wlr8383XPWkNejMxflD01bDCIiLSmVRdgpwHlmtgF4FDjLzP7s7oUeOAg8AExO\nYQyHZcHGnbyxdgdfO30UXTppAHUR6RhSlvjd/UZ3H+LuI4BLgDnu/kUzGwhgwR1Q04DlqYrhcN09\nZw29u3bi8ycNS3coIiItJh398T9sZnmAAYuBq9MQQ6OWF+zmlZXFzJg6jq7ZGrZARDqOVslo7v4q\n8Gr4/KzW2OfhunvOGnp0yeKyU4anOxQRkRalZipxrNq2l+ffKeJLp46gZ5dO6Q5HRKRFqQ4jxuxF\nBdz2wkoKSssxYEDPLukOSUSkxSnxh2YvKuDGJ5dRXlkNgAM3/2MF3Tpn6cYtEelQVNUTuu2FlYeS\nfq3yympue2FlmiISEUkNJf7Q1tLyJs0XEWmvlPhDg3JzmjRfRKS9UuIPzZg6rl7PmzmdMpkxdVya\nIhIRSQ0l/tC0SYPJ655N56wMDBicm8MtF0zQhV0R6XDUqidUuLucoj0H+Z9PHsX000enOxwRkZRR\niT/02qoSAE4/Mn09gYqItAYl/tDc1cUM6NmZcQN6pDsUEZGUUuIHqmucf68u4cNj8wg6DRUR6biU\n+IElW0rZXV6pah4RiQQlfmDeqmLM4MNj+qU7FBGRlFPiJ0j8xw7JpXe37HSHIiKScpFP/Lv3V7J4\ncylnjFVpX0SiIfKJ//W1JdS4mnGKSHREPvHPW1VMjy5ZTByam+5QRERaRaQTv7szb1UxU0b3Iysz\n0m+FiERIpLPd2uIytu4+oGoeEYmUlCd+M8s0s0Vm9mw4PdLM3jSzNWb2VzNLW1OaV1cWA3D6kbqw\nKyLR0Rol/uuAFTHTvwDudPcxwC7gqlaIIa55q0sYldeNIb27pisEEZFWl9LEb2ZDgHOB+8NpA84C\nnghfMguYlsoYEjlQWc2b63Zw+lhV84hItKS6xP8r4AdATTjdFyh196pwegsQt8N7M5tuZvPNbH5x\ncXGLB/bW+p0crKrhjHFK/CISLSlL/Gb2KWC7uy9ozvrufq+757t7fl5eyyfneauKyc7K4OSRfVt8\n2yIibVkqB2KZApxnZp8EugA9gV8DuWaWFZb6hwAFKYwhoXmri5k8og852Znp2L2ISNqkrMTv7je6\n+xB3HwFcAsxx9y8ArwCfDV92BfB0qmJIpHB3Oau2lak1j4hEUjra8V8PfNfM1hDU+f+htQPQaFsi\nEmWtMuauu78KvBo+XwdMbo39JjJ3lUbbEpHoitydu9U1zr/XaLQtEYmuyCV+jbYlIlEXucSv0bZE\nJOoimfg12paIRFmkEr9G2xIRiVji12hbIiIRS/wabUtEJEKJ392Zq9G2RESik/jXbC+jUKNtiYhE\nJ/HPXaXRtkREIEKJf97qEkZrtC0RkWgk/kOjbamaR0QkGom/drQtJX4RkYgkfo22JSLyvmgkfo22\nJSJySIdP/FtLNdqWiEisDp/4X1td24xT9fsiIhCBxD9vVYlG2xIRidFhE//sRQWcOvNl/rGskL0H\nqnh68dZ0hyQi0ia0ypi7rW32ogJufHIZ5ZXVAOyvqObGJ5cBMG3S4HSGJiKSdikr8ZtZFzN7y8yW\nmNk7ZvaTcP6fzGy9mS0OHxNbet+3vbDyUNKvVV5ZzW0vrGzpXYmItDupLPEfBM5y9zIz6wT828ye\nC5fNcPcnUrXjraXlTZovIhIlKSvxe6AsnOwUPjxV+4s1KDenSfNFRKIkpRd3zSzTzBYD24GX3P3N\ncNHPzGypmd1pZp0TrDvdzOab2fzi4uIm7XfG1HHkdPrgzVo5nTKZMXVcM45CRKRjSWnid/dqd58I\nDAEmm9l44EbgKOBEoA9wfYJ173X3fHfPz8trWhv8aZMGc8sFExicm4MBg3NzuOWCCbqwKyJCK7Xq\ncfdSM3sF+IS73x7OPmhmDwDfT8U+p00arEQvIhJHKlv15JlZbvg8B/gY8J6ZDQznGTANWJ6qGERE\npL5UlvgHArPMLJPgC+Yxd3/WzOaYWR5gwGLg6hTGICIidaQs8bv7UmBSnPlnpWqfIiLSuA7bZYOI\niMSnxC8iEjHm3ir3VB0WMysGNgL9gJI0h5NOUT7+KB87RPv4o3zscHjHP9zd67WHbxeJv5aZzXf3\n/HTHkS5RPv4oHztE+/ijfOyQmuNXVY+ISMQo8YuIREx7S/z3pjuANIvy8Uf52CHaxx/lY4cUHH+7\nquMXEZHD195K/CIicpiU+EVEIqbdJH4z+4SZrTSzNWZ2Q7rjaW1mtsHMloXDVc5PdzypZGZ/NLPt\nZrY8Zl4fM3vJzFaHf3unM8ZUSXDsPzazgpjhSj+ZzhhTycyGmtkrZvZuOGTrdeH8Dn/+Gzj2Fj//\n7aKOP+zobRVBD59bgLeBS9393bQG1orMbAOQ7+4d/kYWMzsdKAMedPfx4bxbgZ3uPjP84u/t7nHH\ncmjPEhz7j4GymC7NO6yw996B7r7QzHoACwh68b2SDn7+Gzj2i2nh899eSvyTgTXuvs7dK4BHgc+k\nOSZJEXefB+ysM/szwKzw+SyCD0SHk+DYI8PdC919Yfh8L7ACGEwEzn8Dx97i2kviHwxsjpneQore\nkDbMgRfNbIGZTU93MGkwwN0Lw+dFwIB0BpMG14bDlf6xI1ZzxGNmIwh6+H2TiJ3/OscOLXz+20vi\nFzjN3Y8HzgGuCasEIsmD+sm2X0fZcu4BRgMTgULgl+kNJ/XMrDvwN+Db7r4ndllHP/9xjr3Fz397\nSfwFwNCY6SHhvMhw94Lw73bgKYLqryjZFjN620Bge5rjaTXuvi0cv7oGuI8Ofu7NrBNB4nvY3Z8M\nZ0fi/Mc79lSc//aS+N8GxprZSDPLBi4BnklzTK3GzLqFF3sws27Ax4nekJXPAFeEz68Ank5jLK2q\nNuGFzqcDn/twSNY/ACvc/Y6YRR3+/Cc69lSc/3bRqgcgbML0KyAT+KO7/yzNIbUaMxtFUMqHYNS0\nRzry8ZvZX4CPEHRHuw34ETAbeAwYRtBF98Xu3uEugiY49o8Q/Mx3YAPwtZj67g7FzE4DXgOWATXh\n7P8hqOvu0Oe/gWO/lBY+/+0m8YuISMtoL1U9IiLSQpT4RUQiRolfRCRilPhFRCJGiV9EJGKU+CXS\nzKw6ptfDxS3Z86uZjYjtZVOkrchKdwAiaVbu7hPTHYRIa1KJXySOcPyDW8MxEN4yszHh/BFmNifs\nMOtlMxsWzh9gZk+Z2ZLwcWq4qUwzuy/sX/1FM8sJX/+tsN/1pWb2aJoOUyJKiV+iLqdOVc/nYpbt\ndvcJwN0Ed40D/AaY5e7HAg8Dd4Xz7wLmuvtxwPHAO+H8scBv3f1DQClwYTj/BmBSuJ2rU3VwIvHo\nzl2JNDMrc/fuceZvAM5y93Vhx1lF7t7XzEoIBsuoDOcXuns/MysGhrj7wZhtjABecvex4fT1QCd3\nv9nMnicYcGU2MNvdy1J8qCKHqMQvkpgneN4UB2OeV/P+dbVzgd8S/Dp428x0vU1ajRK/SGKfi/n7\nn/D5GwS9wwJ8gaBTLYCXga9DMFSomfVKtFEzywCGuvsrwPVAL6Derw6RVFEpQ6Iux8wWx0w/7+61\nTTp7m9lSglL7peG8bwIPmNkMoBj4Ujj/OuBeM7uKoGT/dYJBM+LJBP4cfjkYcJe7l7bYEYk0QnX8\nInFEaXB7iR5V9YiIRIxK/CIiEaMSv4hIxCjxi4hEjBK/iEjEKPGLiESMEr+ISMT8P70/VyTfYuj6\nAAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "4. Two conv with three dense layers - loss\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYIAAAEWCAYAAABrDZDcAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "4. Two conv with three dense layers - testing accuracy\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAX4AAAEWCAYAAABhffzLAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nSUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Parameters of the network: 62006\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}
